{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional preprocessing for LSTM, which uses GloVe instead of BERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import multiprocessing as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import spacy\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(rev):\n",
    "    \"\"\"extra (but minimal) preprocessing for\n",
    "    the LSTM baseline, which uses GloVe vectors\n",
    "    rather than BERT embeddings\"\"\"\n",
    "    text, label = rev\n",
    "    text = nlp(text)\n",
    "    text = [word.lemma_ for word in text]\n",
    "    text = \" \".join(text).lower()\n",
    "    text = re.sub(\"[^a-z]+\", \" \", text)\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    return (text, label)\n",
    "\n",
    "\n",
    "def preprocess_corpus(corpus):\n",
    "    \"\"\"loop through reviews\"\"\"\n",
    "    corpus = [preprocess(c) for c in corpus]\n",
    "    return corpus\n",
    "\n",
    "\n",
    "def make_corpus(df):\n",
    "    \"\"\"separate out text and labels, \n",
    "    then preprocess\"\"\"\n",
    "    text = list(df[\"text\"].values)\n",
    "    labels = list(df[\"labels\"].values)\n",
    "    corp = list(zip(text, labels))\n",
    "    corp = preprocess_corpus(corp)\n",
    "    return corp\n",
    "\n",
    "\n",
    "def check_just_ascii(key):\n",
    "    \"\"\"checks whether words are composed of\n",
    "    only ascii characters; for glove dict\n",
    "    only\"\"\"\n",
    "    codes = [ord(c) for c in key]\n",
    "    try:\n",
    "        if max(codes) < 128:\n",
    "            return True\n",
    "    except:\n",
    "        return False\n",
    "    return False\n",
    "\n",
    "\n",
    "def glove2dict(glove_path):\n",
    "    \"\"\"helper function to retrieve retrieve the\n",
    "    GloVe embeddings\"\"\"\n",
    "    with open(glove_path, encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f, delimiter=\" \", quoting=csv.QUOTE_NONE) #, encoding=\"utf-8\")\n",
    "        embed = {line[0]: np.array(list(map(float, line[1:])))\n",
    "                for line in reader}\n",
    "    return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392000, 5)\n",
      "(98000, 5)\n",
      "(48419, 5)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_json(\"train_df_final.json\")\n",
    "dev_df = pd.read_json(\"dev_df_final.json\")\n",
    "test_df = pd.read_json(\"test_df_final.json\")\n",
    "\n",
    "print(train_df.shape)\n",
    "print(dev_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (392000, 5) 392000\n",
      "dev:  (98000, 5) 98000\n",
      "test:  (48419, 5) 48419\n",
      "fin\n"
     ]
    }
   ],
   "source": [
    "cols = [\"text\", \"labels\"]\n",
    "\n",
    "train_corpus = make_corpus(train_df)\n",
    "print(\"train: \", train_df.shape, len(train_corpus))\n",
    "train_corpus = pd.DataFrame(train_corpus, columns=cols)\n",
    "train_corpus.to_json(\"train_df_final_LSTM.json\")\n",
    "\n",
    "dev_corpus = make_corpus(dev_df)\n",
    "print(\"dev: \", dev_df.shape, len(dev_corpus))\n",
    "dev_corpus = pd.DataFrame(dev_corpus, columns=cols)\n",
    "dev_corpus.to_json(\"dev_df_final_LSTM.json\")\n",
    "\n",
    "test_corpus = make_corpus(test_df)\n",
    "print(\"test: \", test_df.shape, len(test_corpus))\n",
    "test_corpus = pd.DataFrame(test_corpus, columns=cols)\n",
    "test_corpus.to_json(\"test_df_final_LSTM.json\")\n",
    "\n",
    "print(\"fin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"glove.42B.300d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = \"glove.42B.300d/glove.42B.300d.txt\"\n",
    "glove_base = glove2dict(glove_path)\n",
    "glove_base = {key:value for key, value in glove_base.items()}\n",
    "\n",
    "glove_ascii_keys = [key for key in glove_base.keys() if check_just_ascii(key)]\n",
    "glove_reduced_keys = [(key, re.sub(\"[^a-z]+\", \"\", key)) for key in glove_ascii_keys if re.sub(\"[^a-z]+\", \"\", key)]\n",
    "glove_reduced = {tup[1]:glove_base[tup[0]] for tup in sorted(glove_reduced_keys)} # overwrites duplicates, e.g. '#the' and 'the'\n",
    "\n",
    "pickle.dump(glove_reduced, open(\"glove_lower_lg.d\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
